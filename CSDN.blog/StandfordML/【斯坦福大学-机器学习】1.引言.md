Author：kevinelstri <br>
DateTime：2017/3/14

----------
#1、机器学习是什么？
&#160;&#160;&#160;&#160;&#160;&#160;Arthur Samuel (1959). Machine Learning: Field of study that gives computers the ability to learn without being explicitly programmed.<br> 

&#160;&#160;&#160;&#160;&#160;&#160;Arthur Samuel:在进行特定编程的情况下，给予计算机学习能力的领域。

&#160;&#160;&#160;&#160;&#160;&#160;Tom Mitchell (1998) Well-posed Learning Problem: A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E. <br>

&#160;&#160;&#160;&#160;&#160;&#160;Tom Mitchell：一个程序被认为能从经验E中学习，解决任务T，达到性能度量值P，当且仅当，有了经验E后，经过P评判，程序在处理T时的性能有所提升。

- E(Experience)：程序进行上万次的自我学习的经验<br>
- T(Task)：完成某项工作<br>
- P(Performance)：这项工作完成的概率，好坏

#2、监督学习
**<font color='red'>案例1</font>**：Housing price prediction(回归问题)
![](http://i.imgur.com/vcOH01y.png)
说明：<br>
&#160;&#160;&#160;&#160;&#160;&#160;横轴表示房子的面积，单位是平方英尺，纵轴表示房价，单位是千美元。<br>
问题：<br>
&#160;&#160;&#160;&#160;&#160;&#160;假如你的朋友有一套750平方英尺房子，希望把房子卖掉，能卖多少钱？
方法1：
&#160;&#160;&#160;&#160;&#160;&#160;拟合一条直线，可以推测这套房子可以卖$150,000<br>

方法2：
&#160;&#160;&#160;&#160;&#160;&#160;使用二次方程来拟合，效果可能会更好，此时可以预测这套房子可以卖$200,000

**<font color='red'>案例2</font>**：Breast cancer(malignant,benign)(分类问题)
![](http://i.imgur.com/GITdmQf.png)
说明：<br>
&#160;&#160;&#160;&#160;&#160;&#160;横轴表示肿瘤的大小，纵轴标出0和1，表示是或不是恶性肿瘤。如果是恶性肿瘤，标记为1，如果不是恶性，或者说是良性，标记为0.<br>
问题：<br>
&#160;&#160;&#160;&#160;&#160;&#160;如果一个朋友查出是乳腺肿瘤，那么根据她的乳腺肿瘤的大小就可以估算她的肿瘤是良性的还是恶性的概率。<br>
讨论：<br>
&#160;&#160;&#160;&#160;&#160;&#160;此时离散的输出值只有两个：0或1，良性或恶性；而事实上分类问题中，输出可能不止两个值，可能有三种乳腺癌，那就可以表示为：0--良性，1--第一类乳腺癌，2--第二类乳腺癌，3--第三类乳腺癌

**<font color='red'>案例3</font>**：多特征分类
![](http://i.imgur.com/7b1t06i.png)
说明：<br>
&#160;&#160;&#160;&#160;&#160;&#160;总共5种不同的特征，坐标轴上的2种和右边的3种.<br>
问题：<br>
&#160;&#160;&#160;&#160;&#160;&#160;在实际的学习问题中，可能不仅仅只有这么几种特征，可能会有无限多种特征，那么你就需要利用这些大量的特征进行学习，推测相关的结果。那该怎么处理无限多个特征，甚至怎么存储这些特征都将存在问题。<br>
方法：<br>
&#160;&#160;&#160;&#160;&#160;&#160;支持向量机，就具有一个巧妙地数学技巧，能让计算机处理无线多个特征。

#3、非监督学习
**<font color='red'>案例1</font>：**监督性学习和非监督性学习的区别
![](http://i.imgur.com/TVdZIFu.png)
说明：<br>
&#160;&#160;&#160;&#160;&#160;&#160;在左图的数据集中，每条数据都已经被标记为阴性或阳性，也就是良性或恶性肿瘤，所以对于监督学习，就是已知训练集对应的答案，也就是良性或恶性。<br>
&#160;&#160;&#160;&#160;&#160;&#160;在右图的数据集中，所有的数据看起来都是一样的，没有任何的标签或者是有相同的标签或者就是没标签，这就是无监督学习，从一堆无标签的数据中进行对数据分类，分成两个不同的簇，叫做聚类算法。

**<font color='red'>案例2</font>：**基因序列
![](http://i.imgur.com/6BRdr6s.png)
说明：<br>
&#160;&#160;&#160;&#160;&#160;&#160;这是一个DNA微观数据的例子，基本思想就是输入一组不同个体，对其中的每个个体，要分析出它们是否有一个特定的基因，分析多少特定的基因已经表达，所以这些颜色就显示了相应的程度，即不同的个体是否有一个特定的基因。运用聚类算法，就可以把个体聚类到不同的类或不同类型的组。

**<font color='red'>案例3</font>：**鸡尾酒宴会
![](http://i.imgur.com/fE5TvS3.png)
说明：<br>
&#160;&#160;&#160;&#160;&#160;&#160;麦克风记录下两个不同的声音，虽然是同样的两个人说话，但是听起来两份声音叠加起来，就产生了重叠的声音。将这个声音进行分离，就需要使用无监督的聚类算法。
分析：<br>
&#160;&#160;&#160;&#160;&#160;&#160;对于这个问题，似乎是为了构建一个应用，首先需要处理音频，使用处理音频的库，才能将其分离开。
而实际上，对于这个算法问题只需要一行代码就可以实现：[W,s,v]=svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x')<br>
讨论：<br>
&#160;&#160;&#160;&#160;&#160;&#160;本次课程使用Octave编程环境，Octave是免费的开源软件。